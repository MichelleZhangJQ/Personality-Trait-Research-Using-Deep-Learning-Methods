{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ecacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d1aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import keras\n",
    "from tensorflow.compat.v1.keras import layers\n",
    "from tensorflow.compat.v1.keras.layers import Lambda, Input, Dense ,Input, Flatten, Multiply, Reshape, concatenate\n",
    "from tensorflow.compat.v1.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.compat.v1.keras.utils import plot_model\n",
    "from  tensorflow.compat.v1.keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras.layers import Dense, Activation, Dropout,Conv1D, MaxPooling1D, Conv2DTranspose, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3eaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "import seaborn as sn\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import umap\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f534c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family': 'serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ac85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.compat.v1.keras.initializers import glorot_uniform  # Or your initializer of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602eb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed778dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer, Rotator\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5880a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jianqiuzhang/opt/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6554544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f99e3b92b10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define computing resource\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "353832bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(m_v):\n",
    "\n",
    "    z_mean, z_log_var = m_v #(mean and var)\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    sample = z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112e0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fname, **kwargs):\n",
    "      f = open(fname, \"wt\")\n",
    "      for k, v in kwargs.items():\n",
    "        print >>f, \"%s=%s\" % (k, repr(v))\n",
    "      f.close()\n",
    "\n",
    "def load(fname):\n",
    "      ret = {}\n",
    "      for line in open(fname, \"rt\"):\n",
    "        k, v = line.strip().split(\"=\", 1)\n",
    "        ret[k] = eval(v)\n",
    "      return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6360a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(mask_data):\n",
    "    inputs, outputs_unmasked =mask_data\n",
    "    mask = tf.math.logical_not(tf.math.equal(inputs, 0))\n",
    "    mask = tf.cast(mask, dtype=outputs_unmasked.dtype) #convert it to the same data type as the outputs_unmasked\n",
    "    outputs_masked= outputs_unmasked*mask\n",
    "    return outputs_masked\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddcf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTheDict(dictObj, callback):\n",
    "    newDict = dict()\n",
    "    for (key, value) in dictObj.items():\n",
    "        if callback((key, value)):\n",
    "            newDict[key] = value\n",
    "    return newDict\n",
    "\n",
    "def vae_loss(true, pred):\n",
    "\n",
    "    reconstruction_loss = mse(K.flatten(true), K.flatten(pred)) * 79\n",
    "\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = 0.5 * reconstruction_loss + beta * 0.5 * kl_loss\n",
    "\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5414783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jianqiuzhang/Documents/Psychology/HEXACO'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb67f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/jianqiuzhang/Documents/Psychology/HEXACO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6914fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HSinc5', 'HMode5', 'HGree10', 'HSinc3', 'HGree4', 'AGent10', 'AGent8', 'HFair7', 'HSinc7', 'EAnxi4', 'EDepe1', 'EAnxi5', 'EAnxi2', 'EAnxi3', 'EAnxi1', 'EAnxi6', 'ESent10', 'EDepe8', 'CPrud3', 'CPrud2', 'COrga1', 'COrga3', 'CPerf2', 'COrga4', 'CDili3', 'CPrud1', 'CDili1', 'XSoci8', 'XSoci1', 'XExpr6', 'XSoci6', 'XSoci3', 'XExpr8', 'XSocB3', 'XSocB2', 'XExpr1', 'OCrea4', 'OCrea8', 'OCrea7', 'OUnco2', 'OInqu4', 'OCrea2', 'OAesA5', 'OCrea1', 'OInqu8', 'AForg4', 'HSinc10', 'APati1', 'AForg1', 'APati3', 'APati2', 'APati5', 'APati4', 'AGent4', 'EFear6', 'EFear8', 'EFear9', 'EFear10', 'EFear5', 'EFear3', 'OInqu2', 'OAesA9', 'OAesA4', 'OInqu9', 'OInqu5', 'HGree2', 'OInqu10', 'AGent2', 'CPrud4', 'CPerf10', 'CPrud5', 'CPrud9', 'OAesA6', 'OAesA10', 'OInqu1', 'OAesA7', 'OInqu3', 'OAesA1', 'ESent6']\n"
     ]
    }
   ],
   "source": [
    "col_keys=pd.read_csv('keys_new12')\n",
    "col_keys=list(col_keys.iloc[:,1])\n",
    "print(col_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3fd8c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianqiuzhang/opt/miniconda3/envs/tf/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (243) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HSinc5</th>\n",
       "      <th>HMode5</th>\n",
       "      <th>HGree10</th>\n",
       "      <th>HSinc3</th>\n",
       "      <th>HGree4</th>\n",
       "      <th>AGent10</th>\n",
       "      <th>AGent8</th>\n",
       "      <th>HFair7</th>\n",
       "      <th>HSinc7</th>\n",
       "      <th>EAnxi4</th>\n",
       "      <th>...</th>\n",
       "      <th>CPerf10</th>\n",
       "      <th>CPrud5</th>\n",
       "      <th>CPrud9</th>\n",
       "      <th>OAesA6</th>\n",
       "      <th>OAesA10</th>\n",
       "      <th>OInqu1</th>\n",
       "      <th>OAesA7</th>\n",
       "      <th>OInqu3</th>\n",
       "      <th>OAesA1</th>\n",
       "      <th>ESent6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22781</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22782</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22783</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22784</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22785</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18779 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HSinc5  HMode5  HGree10  HSinc3  HGree4  AGent10  AGent8  HFair7  \\\n",
       "0           2       5        2       5       2        6       5       1   \n",
       "1           5       4        6       5       2        5       5       5   \n",
       "2           5       6        3       6       4        4       3       2   \n",
       "3           6       5        6       3       3        4       3       5   \n",
       "4           2       6        4       5       5        3       3       7   \n",
       "...       ...     ...      ...     ...     ...      ...     ...     ...   \n",
       "22781       7       7        1       1       1        1       2       1   \n",
       "22782       1       4        3       2       3        3       3       3   \n",
       "22783       1       1        1       1       1        1       1       1   \n",
       "22784       1       7        2       5       6        2       3       1   \n",
       "22785       1       6        5       6       5        2       2       1   \n",
       "\n",
       "       HSinc7  EAnxi4  ...  CPerf10  CPrud5  CPrud9  OAesA6  OAesA10  OInqu1  \\\n",
       "0           6       2  ...        2       2       5       1        2       7   \n",
       "1           5       3  ...        3       5       5       1        4       5   \n",
       "2           2       3  ...        6       2       6       1        2       5   \n",
       "3           5       6  ...        5       6       6       2        4       6   \n",
       "4           1       5  ...        6       5       4       1        5       5   \n",
       "...       ...     ...  ...      ...     ...     ...     ...      ...     ...   \n",
       "22781       4       5  ...        7       6       7       1        7       7   \n",
       "22782       3       3  ...        5       4       4       4        3       5   \n",
       "22783       1       1  ...        2       2       1       1        2       2   \n",
       "22784       1       7  ...        3       1       4       1        1       7   \n",
       "22785       5       1  ...        2       1       1       1        2       6   \n",
       "\n",
       "       OAesA7  OInqu3  OAesA1  ESent6  \n",
       "0           6       5       5       7  \n",
       "1           5       7       7       3  \n",
       "2           2       5       6       6  \n",
       "3           4       6       6       6  \n",
       "4           2       3       5       7  \n",
       "...       ...     ...     ...     ...  \n",
       "22781       6       6       7       7  \n",
       "22782       3       6       4       7  \n",
       "22783       1       7       7       1  \n",
       "22784       5       7       7       3  \n",
       "22785       1       6       7       2  \n",
       "\n",
       "[18779 rows x 79 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data_read = pd.read_table('/Users/jianqiuzhang/Documents/Psychology/HEXACO/data.csv')\n",
    "col_name = list(data_read.columns)\n",
    "data = data_read.iloc[:,col_name.index('HSinc1'):col_name.index('OUnco10')+1]\n",
    "quality = data_read.iloc[:,col_name.index('V1'):col_name.index('V2')+1]\n",
    "dropi=quality.query(('V1 < 7') or ('V2<7') ).index\n",
    "dropindex=list(dropi)\n",
    "#col_drop=col_name[col_name.index('F1'):col_name.index('N10')+1]\n",
    "dropdata=data.drop(dropindex,axis=0)\n",
    "\n",
    "#col_names = list(dropdata.columns)\n",
    "#col_random=random.sample(col_names,len(col_names))\n",
    "col_random=col_keys\n",
    "#col_randomdf=pd.DataFrame(col_random)\n",
    "#col_randomdf.to_csv('col_random')\n",
    "#col_randomdf=pd.read_csv('col_random')\n",
    "#col_random=list(col_randomdf.iloc[:,1])\n",
    "dropdata=dropdata[col_random]\n",
    "exp_data=dropdata.values\n",
    "\n",
    "dropdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2208f80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianqiuzhang/opt/miniconda3/envs/tf/lib/python3.7/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Code             XExpr1\n",
       "Content     talk a lot.\n",
       "Name: XExpr1, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_book = pd.read_table('/Users/jianqiuzhang/Documents/Psychology/HEXACO/codebookItems.txt',delimiter=' I')\n",
    "code_book.set_index('Code')\n",
    "code_book.columns=list(['Code','Content'])\n",
    "codes=list(code_book['Code'])\n",
    "content=code_book['Content']\n",
    "code_book.index=codes\n",
    "code_book.drop(['Code'], axis=1)\n",
    "code_book.loc['XExpr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f724191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "zeroindex=(exp_data==0)\n",
    "scaler = StandardScaler()\n",
    "scaled_exp_data_df=dropdata.copy()\n",
    "scaled_exp_data_df=pd.DataFrame(scaler.fit_transform(scaled_exp_data_df), columns=dropdata.columns)\n",
    "scaled_exp_data=scaled_exp_data_df.values\n",
    "scaled_exp_data[zeroindex]=0\n",
    "scaled_X_train, scaled_X_test=train_test_split(scaled_exp_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f981121",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper params\n",
    "input_nodes=79\n",
    "latent_dim =12\n",
    "hidden_nodes=160\n",
    "hidden_nodes2=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "872ba3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAE model\n",
    "# build encoder\n",
    "inputs = Input(shape=(input_nodes,), name='encoder_input')\n",
    "block1 = Dense(hidden_nodes, kernel_initializer='he_normal', activation='relu')(inputs)\n",
    "block1 = BatchNormalization(axis=-1)(block1)\n",
    "flatten = Flatten()(block1)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(flatten)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(flatten)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "183e9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick\n",
    "x = [z_mean, z_log_var]\n",
    "z = Lambda(sampling, name='z_sample')(x)\n",
    "\n",
    "# instantiate encoder\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65f64ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "de_block1 = Dense(hidden_nodes, activation='relu')(latent_inputs)\n",
    "de_block1 = BatchNormalization()(de_block1)\n",
    "outputs_unmasked = Dense(input_nodes, activation='linear')(de_block1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "915af444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jianqiuzhang/opt/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "embedding = layers.Embedding(input_dim=240, output_dim=240, mask_zero=True)\n",
    "masked_output = embedding(inputs)\n",
    "#print(masked_output._keras_mask)\n",
    "masking_layer = layers.Masking()\n",
    "outputs = masking_layer(outputs_unmasked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3e407b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate decoder\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f609002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 79)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 160)          12800       encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 160)          640         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 160)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 12)           1932        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 12)           1932        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_sample (Lambda)               (None, 12)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,304\n",
      "Trainable params: 16,984\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 160)               2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 79)                12719     \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, 79)                0         \n",
      "=================================================================\n",
      "Total params: 15,439\n",
      "Trainable params: 15,119\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 79)]              0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 12), (None, 12),  17304     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 79)                15439     \n",
      "=================================================================\n",
      "Total params: 32,743\n",
      "Trainable params: 32,103\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# show summary\n",
    "plot_model(vae, to_file='beta-vae.png', show_shapes=True)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8c4ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper params\n",
    "batch_size = 64\n",
    "epochs =100\n",
    "lr = 0.0005\n",
    "decay = 1e-6\n",
    "beta = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7b1a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "adam = Adam(lr = lr, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=decay, amsgrad=True)\n",
    "vae.compile(optimizer= adam, loss = vae_loss, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2830575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = vae.get_weights()\n",
    "\n",
    "backend_name = K.backend()\n",
    "if backend_name == 'tensorflow': \n",
    "    k_eval = lambda placeholder: placeholder.eval(session=K.get_session())\n",
    "elif backend_name == 'theano': \n",
    "    k_eval = lambda placeholder: placeholder.eval()\n",
    "else: \n",
    "    raise ValueError(\"Unsupported backend\")\n",
    "\n",
    "new_weights = [k_eval(glorot_uniform()(w.shape)) for w in initial_weights]\n",
    "\n",
    "vae.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88e101c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10516 samples, validate on 4507 samples\n",
      "Epoch 1/100\n",
      "10516/10516 - 5s - loss: 39.6693 - acc: 0.0146 - val_loss: nan - val_acc: 0.0149\n",
      "Epoch 2/100\n",
      "10516/10516 - 2s - loss: 35.0091 - acc: 0.0488 - val_loss: 31.8073 - val_acc: 0.0659\n",
      "Epoch 3/100\n",
      "10516/10516 - 2s - loss: 30.8205 - acc: 0.0687 - val_loss: 29.8306 - val_acc: 0.0746\n",
      "Epoch 4/100\n",
      "10516/10516 - 2s - loss: 29.5244 - acc: 0.0845 - val_loss: 28.6847 - val_acc: 0.0996\n",
      "Epoch 5/100\n",
      "10516/10516 - 2s - loss: 28.6010 - acc: 0.1056 - val_loss: 28.1220 - val_acc: 0.1109\n",
      "Epoch 6/100\n",
      "10516/10516 - 2s - loss: 28.2425 - acc: 0.1165 - val_loss: 27.8585 - val_acc: 0.1207\n",
      "Epoch 7/100\n",
      "10516/10516 - 2s - loss: 28.0220 - acc: 0.1269 - val_loss: 27.7041 - val_acc: 0.1393\n",
      "Epoch 8/100\n",
      "10516/10516 - 2s - loss: 27.8942 - acc: 0.1317 - val_loss: 27.6359 - val_acc: 0.1294\n",
      "Epoch 9/100\n",
      "10516/10516 - 2s - loss: 27.7664 - acc: 0.1374 - val_loss: 27.4926 - val_acc: 0.1458\n",
      "Epoch 10/100\n",
      "10516/10516 - 2s - loss: 27.6471 - acc: 0.1463 - val_loss: 27.4207 - val_acc: 0.1495\n",
      "Epoch 11/100\n",
      "10516/10516 - 3s - loss: 27.5885 - acc: 0.1480 - val_loss: 27.3024 - val_acc: 0.1531\n",
      "Epoch 12/100\n",
      "10516/10516 - 3s - loss: 27.4721 - acc: 0.1511 - val_loss: 27.2562 - val_acc: 0.1626\n",
      "Epoch 13/100\n",
      "10516/10516 - 2s - loss: 27.3981 - acc: 0.1576 - val_loss: 27.1442 - val_acc: 0.1697\n",
      "Epoch 14/100\n",
      "10516/10516 - 2s - loss: 27.3513 - acc: 0.1600 - val_loss: 27.0652 - val_acc: 0.1655\n",
      "Epoch 15/100\n",
      "10516/10516 - 2s - loss: 27.3037 - acc: 0.1656 - val_loss: 27.0514 - val_acc: 0.1677\n",
      "Epoch 16/100\n",
      "10516/10516 - 3s - loss: 27.2308 - acc: 0.1651 - val_loss: 27.0257 - val_acc: 0.1722\n",
      "Epoch 17/100\n",
      "10516/10516 - 2s - loss: 27.2228 - acc: 0.1721 - val_loss: 26.9947 - val_acc: 0.1742\n",
      "Epoch 18/100\n",
      "10516/10516 - 2s - loss: 27.1247 - acc: 0.1731 - val_loss: 26.9371 - val_acc: 0.1751\n",
      "Epoch 19/100\n",
      "10516/10516 - 2s - loss: 27.1642 - acc: 0.1709 - val_loss: 26.9209 - val_acc: 0.1779\n",
      "Epoch 20/100\n",
      "10516/10516 - 2s - loss: 27.1388 - acc: 0.1767 - val_loss: 26.8986 - val_acc: 0.1802\n",
      "Epoch 21/100\n",
      "10516/10516 - 2s - loss: 27.1102 - acc: 0.1773 - val_loss: 26.8699 - val_acc: 0.1808\n",
      "Epoch 22/100\n",
      "10516/10516 - 2s - loss: 27.0609 - acc: 0.1770 - val_loss: 26.9065 - val_acc: 0.1835\n",
      "Epoch 23/100\n",
      "10516/10516 - 3s - loss: 27.0220 - acc: 0.1812 - val_loss: 26.8499 - val_acc: 0.1848\n",
      "Epoch 24/100\n",
      "10516/10516 - 2s - loss: 27.0461 - acc: 0.1812 - val_loss: 26.8353 - val_acc: 0.1875\n",
      "Epoch 25/100\n",
      "10516/10516 - 2s - loss: 26.9902 - acc: 0.1806 - val_loss: 26.8060 - val_acc: 0.1837\n",
      "Epoch 26/100\n",
      "10516/10516 - 2s - loss: 26.9963 - acc: 0.1783 - val_loss: 26.8163 - val_acc: 0.1857\n",
      "Epoch 27/100\n",
      "10516/10516 - 2s - loss: 26.9520 - acc: 0.1851 - val_loss: 26.7929 - val_acc: 0.1773\n",
      "Epoch 28/100\n",
      "10516/10516 - 2s - loss: 26.9529 - acc: 0.1867 - val_loss: 26.8046 - val_acc: 0.1864\n",
      "Epoch 29/100\n",
      "10516/10516 - 2s - loss: 26.9333 - acc: 0.1810 - val_loss: 26.7981 - val_acc: 0.1875\n",
      "Epoch 30/100\n",
      "10516/10516 - 2s - loss: 26.9566 - acc: 0.1888 - val_loss: 26.7737 - val_acc: 0.1848\n",
      "Epoch 31/100\n",
      "10516/10516 - 2s - loss: 26.9181 - acc: 0.1890 - val_loss: 26.7378 - val_acc: 0.1906\n",
      "Epoch 32/100\n",
      "10516/10516 - 3s - loss: 26.9129 - acc: 0.1892 - val_loss: 26.7622 - val_acc: 0.1930\n",
      "Epoch 33/100\n",
      "10516/10516 - 3s - loss: 26.9077 - acc: 0.1937 - val_loss: 26.7476 - val_acc: 0.1917\n",
      "Epoch 34/100\n",
      "10516/10516 - 2s - loss: 26.8818 - acc: 0.1909 - val_loss: 26.7219 - val_acc: 0.1953\n",
      "Epoch 35/100\n",
      "10516/10516 - 3s - loss: 26.8723 - acc: 0.1961 - val_loss: 26.7155 - val_acc: 0.1953\n",
      "Epoch 36/100\n",
      "10516/10516 - 3s - loss: 26.8791 - acc: 0.1909 - val_loss: 26.7361 - val_acc: 0.1948\n",
      "Epoch 37/100\n",
      "10516/10516 - 3s - loss: 26.8387 - acc: 0.1868 - val_loss: 26.6925 - val_acc: 0.1913\n",
      "Epoch 38/100\n",
      "10516/10516 - 3s - loss: 26.8443 - acc: 0.1890 - val_loss: 26.7386 - val_acc: 0.1853\n",
      "Epoch 39/100\n",
      "10516/10516 - 3s - loss: 26.8420 - acc: 0.2000 - val_loss: 26.6919 - val_acc: 0.1890\n",
      "Epoch 40/100\n",
      "10516/10516 - 2s - loss: 26.8274 - acc: 0.1909 - val_loss: 26.6680 - val_acc: 0.1939\n",
      "Epoch 41/100\n",
      "10516/10516 - 3s - loss: 26.8631 - acc: 0.1902 - val_loss: 26.7050 - val_acc: 0.2001\n",
      "Epoch 42/100\n",
      "10516/10516 - 3s - loss: 26.7942 - acc: 0.1937 - val_loss: 26.7116 - val_acc: 0.1888\n",
      "Epoch 43/100\n",
      "10516/10516 - 2s - loss: 26.7879 - acc: 0.1933 - val_loss: 26.6832 - val_acc: 0.1853\n",
      "Epoch 44/100\n",
      "10516/10516 - 2s - loss: 26.8072 - acc: 0.1943 - val_loss: 26.6795 - val_acc: 0.1944\n",
      "Epoch 45/100\n",
      "10516/10516 - 2s - loss: 26.7798 - acc: 0.1913 - val_loss: 26.6190 - val_acc: 0.1913\n",
      "Epoch 46/100\n",
      "10516/10516 - 3s - loss: 26.8099 - acc: 0.1924 - val_loss: 26.6728 - val_acc: 0.1970\n",
      "Epoch 47/100\n",
      "10516/10516 - 3s - loss: 26.7957 - acc: 0.1979 - val_loss: 26.6622 - val_acc: 0.1944\n",
      "Epoch 48/100\n",
      "10516/10516 - 2s - loss: 26.7698 - acc: 0.1948 - val_loss: 26.6738 - val_acc: 0.1957\n",
      "Epoch 49/100\n",
      "10516/10516 - 2s - loss: 26.7644 - acc: 0.1974 - val_loss: 26.6445 - val_acc: 0.1868\n",
      "Epoch 50/100\n",
      "10516/10516 - 3s - loss: 26.7584 - acc: 0.1970 - val_loss: 26.6345 - val_acc: 0.1926\n",
      "Epoch 51/100\n",
      "10516/10516 - 3s - loss: 26.7755 - acc: 0.1971 - val_loss: 26.6587 - val_acc: 0.1917\n",
      "Epoch 52/100\n",
      "10516/10516 - 6s - loss: 26.7313 - acc: 0.1941 - val_loss: 26.6304 - val_acc: 0.1992\n",
      "Epoch 53/100\n",
      "10516/10516 - 3s - loss: 26.7152 - acc: 0.2015 - val_loss: 26.6316 - val_acc: 0.2075\n",
      "Epoch 54/100\n",
      "10516/10516 - 3s - loss: 26.7299 - acc: 0.1951 - val_loss: 26.6315 - val_acc: 0.2024\n",
      "Epoch 55/100\n",
      "10516/10516 - 4s - loss: 26.7039 - acc: 0.2011 - val_loss: 26.5901 - val_acc: 0.2004\n",
      "Epoch 56/100\n",
      "10516/10516 - 2s - loss: 26.7264 - acc: 0.1980 - val_loss: 26.5880 - val_acc: 0.2026\n",
      "Epoch 57/100\n",
      "10516/10516 - 3s - loss: 26.7501 - acc: 0.1964 - val_loss: 26.5832 - val_acc: 0.2021\n",
      "Epoch 58/100\n",
      "10516/10516 - 3s - loss: 26.7115 - acc: 0.2004 - val_loss: 26.6551 - val_acc: 0.1933\n",
      "Epoch 59/100\n",
      "10516/10516 - 3s - loss: 26.7563 - acc: 0.1934 - val_loss: 26.6367 - val_acc: 0.2092\n",
      "Epoch 60/100\n",
      "10516/10516 - 2s - loss: 26.7358 - acc: 0.2000 - val_loss: 26.6081 - val_acc: 0.2068\n",
      "Epoch 61/100\n",
      "10516/10516 - 2s - loss: 26.7246 - acc: 0.1967 - val_loss: 26.6498 - val_acc: 0.2028\n",
      "Epoch 62/100\n",
      "10516/10516 - 2s - loss: 26.7061 - acc: 0.2037 - val_loss: 26.5961 - val_acc: 0.2075\n",
      "Epoch 63/100\n",
      "10516/10516 - 2s - loss: 26.6731 - acc: 0.1984 - val_loss: 26.6037 - val_acc: 0.2015\n",
      "Epoch 64/100\n",
      "10516/10516 - 2s - loss: 26.6722 - acc: 0.2011 - val_loss: 26.6002 - val_acc: 0.1946\n",
      "Epoch 65/100\n",
      "10516/10516 - 2s - loss: 26.7031 - acc: 0.1981 - val_loss: 26.5589 - val_acc: 0.2019\n",
      "Epoch 66/100\n",
      "10516/10516 - 2s - loss: 26.6848 - acc: 0.2018 - val_loss: 26.5936 - val_acc: 0.1972\n",
      "Epoch 67/100\n",
      "10516/10516 - 2s - loss: 26.6747 - acc: 0.1976 - val_loss: 26.5750 - val_acc: 0.1910\n",
      "Epoch 68/100\n",
      "10516/10516 - 2s - loss: 26.6784 - acc: 0.1989 - val_loss: 26.6218 - val_acc: 0.2001\n",
      "Epoch 69/100\n",
      "10516/10516 - 2s - loss: 26.6665 - acc: 0.2015 - val_loss: 26.5732 - val_acc: 0.1977\n",
      "Epoch 70/100\n",
      "10516/10516 - 2s - loss: 26.6623 - acc: 0.2013 - val_loss: 26.6239 - val_acc: 0.2030\n",
      "Epoch 71/100\n",
      "10516/10516 - 2s - loss: 26.6633 - acc: 0.2049 - val_loss: 26.5726 - val_acc: 0.2017\n",
      "Epoch 72/100\n",
      "10516/10516 - 2s - loss: 26.6791 - acc: 0.1974 - val_loss: 26.5859 - val_acc: 0.1968\n",
      "Epoch 73/100\n",
      "10516/10516 - 2s - loss: 26.6517 - acc: 0.2084 - val_loss: 26.5447 - val_acc: 0.2030\n",
      "Epoch 74/100\n",
      "10516/10516 - 2s - loss: 26.6715 - acc: 0.2015 - val_loss: 26.5672 - val_acc: 0.1990\n",
      "Epoch 75/100\n",
      "10516/10516 - 2s - loss: 26.6896 - acc: 0.2031 - val_loss: 26.5573 - val_acc: 0.2006\n",
      "Epoch 76/100\n",
      "10516/10516 - 2s - loss: 26.6189 - acc: 0.2052 - val_loss: 26.5633 - val_acc: 0.2021\n",
      "Epoch 77/100\n",
      "10516/10516 - 2s - loss: 26.6697 - acc: 0.2041 - val_loss: 26.5505 - val_acc: 0.1986\n",
      "Epoch 78/100\n",
      "10516/10516 - 2s - loss: 26.6332 - acc: 0.2043 - val_loss: 26.5844 - val_acc: 0.1950\n",
      "Epoch 79/100\n",
      "10516/10516 - 2s - loss: 26.6403 - acc: 0.2042 - val_loss: 26.5486 - val_acc: 0.2079\n",
      "Epoch 80/100\n",
      "10516/10516 - 3s - loss: 26.6446 - acc: 0.2038 - val_loss: 26.5248 - val_acc: 0.2050\n",
      "Epoch 81/100\n",
      "10516/10516 - 2s - loss: 26.6464 - acc: 0.2039 - val_loss: 26.5418 - val_acc: 0.2037\n",
      "Epoch 82/100\n",
      "10516/10516 - 3s - loss: 26.6409 - acc: 0.2045 - val_loss: 26.5277 - val_acc: 0.2068\n",
      "Epoch 83/100\n",
      "10516/10516 - 3s - loss: 26.6401 - acc: 0.2023 - val_loss: 26.5371 - val_acc: 0.2083\n",
      "Epoch 84/100\n",
      "10516/10516 - 3s - loss: 26.6160 - acc: 0.2028 - val_loss: 26.5579 - val_acc: 0.2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "10516/10516 - 3s - loss: 26.6193 - acc: 0.2028 - val_loss: 26.5602 - val_acc: 0.2024\n",
      "Epoch 86/100\n",
      "10516/10516 - 2s - loss: 26.6295 - acc: 0.2107 - val_loss: 26.5633 - val_acc: 0.2097\n",
      "Epoch 87/100\n",
      "10516/10516 - 2s - loss: 26.5939 - acc: 0.2013 - val_loss: 26.5173 - val_acc: 0.2015\n",
      "Epoch 88/100\n",
      "10516/10516 - 2s - loss: 26.6031 - acc: 0.1997 - val_loss: 26.5302 - val_acc: 0.2092\n",
      "Epoch 89/100\n",
      "10516/10516 - 2s - loss: 26.5758 - acc: 0.2052 - val_loss: 26.5812 - val_acc: 0.1930\n",
      "Epoch 90/100\n",
      "10516/10516 - 2s - loss: 26.5837 - acc: 0.2032 - val_loss: 26.5706 - val_acc: 0.2028\n",
      "Epoch 91/100\n",
      "10516/10516 - 2s - loss: 26.6035 - acc: 0.2077 - val_loss: 26.5522 - val_acc: 0.2015\n",
      "Epoch 92/100\n",
      "10516/10516 - 2s - loss: 26.5847 - acc: 0.2082 - val_loss: 26.5420 - val_acc: 0.2039\n",
      "Epoch 93/100\n",
      "10516/10516 - 3s - loss: 26.6024 - acc: 0.2033 - val_loss: 26.5282 - val_acc: 0.2043\n",
      "Epoch 94/100\n",
      "10516/10516 - 2s - loss: 26.5764 - acc: 0.2066 - val_loss: 26.5566 - val_acc: 0.2006\n",
      "Epoch 95/100\n",
      "10516/10516 - 2s - loss: 26.6007 - acc: 0.2025 - val_loss: 26.5352 - val_acc: 0.2063\n",
      "Epoch 96/100\n",
      "10516/10516 - 2s - loss: 26.5842 - acc: 0.2053 - val_loss: 26.5304 - val_acc: 0.2035\n",
      "Epoch 97/100\n",
      "10516/10516 - 2s - loss: 26.6151 - acc: 0.2061 - val_loss: 26.5125 - val_acc: 0.2139\n",
      "Epoch 98/100\n",
      "10516/10516 - 2s - loss: 26.6107 - acc: 0.2045 - val_loss: 26.5178 - val_acc: 0.2083\n",
      "Epoch 99/100\n",
      "10516/10516 - 2s - loss: 26.5454 - acc: 0.2049 - val_loss: 26.5279 - val_acc: 0.2041\n",
      "Epoch 100/100\n",
      "10516/10516 - 2s - loss: 26.5717 - acc: 0.2019 - val_loss: 26.5172 - val_acc: 0.2101\n"
     ]
    }
   ],
   "source": [
    "hist = vae.fit(scaled_X_train, scaled_X_train, epochs=epochs, batch_size=batch_size, validation_split=0.3, shuffle=True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e5f5876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is: 0.5371450304919478\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reconstruction performance\n",
    "latent_pred = encoder.predict(scaled_X_test)[2]\n",
    "recon= decoder.predict(latent_pred)\n",
    "#recon = vae.predict(scaled_X_test)\n",
    "recon_loss_1 = ((scaled_X_test - recon) ** 2).mean(axis=1)\n",
    "plt.hist(recon_loss_1)\n",
    "plt.title(' Reconstruction MSE ', fontdict=font)\n",
    "recon_loss = ((scaled_X_test - recon) ** 2).mean(axis=None)\n",
    "format_float = \"{:.3f}\".format(recon_loss)\n",
    "print_text='MSE/Element is: '+str(format_float)\n",
    "xpos=0.75\n",
    "ytop=1000\n",
    "ystep=150\n",
    "plt.text(xpos-0.05, ytop, print_text, fontdict=font)\n",
    "plt.text(xpos, ytop-ystep, '12 Factors', fontdict=font)\n",
    "plt.text(xpos, ytop-ystep*2, node + ' Middle Layer Nodes', fontdict=font)\n",
    "plt.xlabel('Mean Square Error/Sample', fontdict=font)\n",
    "plt.ylabel('Frequency', fontdict=font)\n",
    "print('MSE is:', recon_loss)\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('Big5MSEHist1ReluGreat1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db0edac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss vae: 26.645489248858727\n"
     ]
    }
   ],
   "source": [
    "loss,_  = vae.evaluate(scaled_X_test, scaled_X_test, batch_size=64, verbose=0)\n",
    "\n",
    "print('Test loss vae:', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a908f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.save('Big12Hexaco79Layer1DecoderReluCopy1.h5')\n",
    "encoder.save('Big12Hexaco79Layer1EncoderReluCopy1.h5')\n",
    "#vae.save('HexacovaeGood2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b706a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Big12Hexaco79Layer1DecoderReluCopy1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder=keras.models.load_model('/Users/jianqiuzhang/Documents/Psychology/HEXACO/Big12Hexaco79Layer1DecoderReluCopy3.h5')\n",
    "#encoder=keras.models.load_model('/Users/jianqiuzhang/Documents/Psychology/HEXACO/Big12Hexaco79Layer1DecoderReluCopy3.h5')\n",
    "#scaled_X_train, scaled_X_test=train_test_split(scaled_exp_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8572eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>CPerf10</th>\n",
       "      <th>CPrud5</th>\n",
       "      <th>CPrud9</th>\n",
       "      <th>OAesA6</th>\n",
       "      <th>OAesA10</th>\n",
       "      <th>OInqu1</th>\n",
       "      <th>OAesA7</th>\n",
       "      <th>OInqu3</th>\n",
       "      <th>OAesA1</th>\n",
       "      <th>ESent6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.547340</td>\n",
       "      <td>0.321155</td>\n",
       "      <td>-0.521609</td>\n",
       "      <td>-0.667134</td>\n",
       "      <td>1.194584</td>\n",
       "      <td>0.616334</td>\n",
       "      <td>0.952861</td>\n",
       "      <td>0.101727</td>\n",
       "      <td>-0.934818</td>\n",
       "      <td>-1.044904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474098</td>\n",
       "      <td>-0.721388</td>\n",
       "      <td>-0.285091</td>\n",
       "      <td>0.083817</td>\n",
       "      <td>0.646170</td>\n",
       "      <td>0.278937</td>\n",
       "      <td>0.838833</td>\n",
       "      <td>0.175011</td>\n",
       "      <td>-0.513915</td>\n",
       "      <td>0.754597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.179351</td>\n",
       "      <td>-0.186618</td>\n",
       "      <td>-0.383540</td>\n",
       "      <td>0.521422</td>\n",
       "      <td>0.035439</td>\n",
       "      <td>-0.219021</td>\n",
       "      <td>-0.590066</td>\n",
       "      <td>-0.723844</td>\n",
       "      <td>-0.279441</td>\n",
       "      <td>-0.971966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116680</td>\n",
       "      <td>-0.243137</td>\n",
       "      <td>-0.081703</td>\n",
       "      <td>-0.381048</td>\n",
       "      <td>-0.275011</td>\n",
       "      <td>0.474022</td>\n",
       "      <td>-0.250842</td>\n",
       "      <td>0.422628</td>\n",
       "      <td>0.445666</td>\n",
       "      <td>0.332045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.822423</td>\n",
       "      <td>0.548955</td>\n",
       "      <td>0.388522</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>-0.212613</td>\n",
       "      <td>0.096057</td>\n",
       "      <td>1.051729</td>\n",
       "      <td>0.317545</td>\n",
       "      <td>-0.561819</td>\n",
       "      <td>0.342269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396497</td>\n",
       "      <td>0.136460</td>\n",
       "      <td>0.269999</td>\n",
       "      <td>-0.344447</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.252842</td>\n",
       "      <td>-0.041309</td>\n",
       "      <td>0.306829</td>\n",
       "      <td>0.291497</td>\n",
       "      <td>0.371646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316304</td>\n",
       "      <td>-0.021830</td>\n",
       "      <td>0.921788</td>\n",
       "      <td>-0.440276</td>\n",
       "      <td>-0.773590</td>\n",
       "      <td>0.108143</td>\n",
       "      <td>0.597496</td>\n",
       "      <td>0.309328</td>\n",
       "      <td>-0.112767</td>\n",
       "      <td>0.348973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329783</td>\n",
       "      <td>0.600764</td>\n",
       "      <td>0.424140</td>\n",
       "      <td>-0.102456</td>\n",
       "      <td>0.527801</td>\n",
       "      <td>-0.461691</td>\n",
       "      <td>0.799929</td>\n",
       "      <td>-0.687216</td>\n",
       "      <td>-0.215589</td>\n",
       "      <td>0.205739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.079486</td>\n",
       "      <td>0.536734</td>\n",
       "      <td>0.968131</td>\n",
       "      <td>0.749729</td>\n",
       "      <td>-0.760875</td>\n",
       "      <td>1.116711</td>\n",
       "      <td>0.156330</td>\n",
       "      <td>-0.349707</td>\n",
       "      <td>0.796320</td>\n",
       "      <td>1.484557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.728974</td>\n",
       "      <td>0.152728</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.042695</td>\n",
       "      <td>-1.186207</td>\n",
       "      <td>0.415763</td>\n",
       "      <td>-1.451052</td>\n",
       "      <td>-0.276623</td>\n",
       "      <td>-0.032219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18774</th>\n",
       "      <td>1.010972</td>\n",
       "      <td>-0.970312</td>\n",
       "      <td>-0.305139</td>\n",
       "      <td>0.319521</td>\n",
       "      <td>0.721568</td>\n",
       "      <td>-1.896508</td>\n",
       "      <td>2.487564</td>\n",
       "      <td>1.883651</td>\n",
       "      <td>-1.879294</td>\n",
       "      <td>0.393940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903710</td>\n",
       "      <td>0.234680</td>\n",
       "      <td>0.801625</td>\n",
       "      <td>-0.212077</td>\n",
       "      <td>0.811664</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.498172</td>\n",
       "      <td>0.862597</td>\n",
       "      <td>0.248693</td>\n",
       "      <td>0.861389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18775</th>\n",
       "      <td>-0.278320</td>\n",
       "      <td>0.159152</td>\n",
       "      <td>0.674553</td>\n",
       "      <td>0.703293</td>\n",
       "      <td>0.929658</td>\n",
       "      <td>-0.912538</td>\n",
       "      <td>-0.849352</td>\n",
       "      <td>0.705957</td>\n",
       "      <td>-0.800981</td>\n",
       "      <td>1.010020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031123</td>\n",
       "      <td>-0.192895</td>\n",
       "      <td>-0.792991</td>\n",
       "      <td>1.365654</td>\n",
       "      <td>0.582033</td>\n",
       "      <td>0.206594</td>\n",
       "      <td>0.773841</td>\n",
       "      <td>0.064626</td>\n",
       "      <td>-1.269274</td>\n",
       "      <td>0.423509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18776</th>\n",
       "      <td>-1.290143</td>\n",
       "      <td>0.638520</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.290224</td>\n",
       "      <td>1.114895</td>\n",
       "      <td>0.539747</td>\n",
       "      <td>-0.968946</td>\n",
       "      <td>-1.738070</td>\n",
       "      <td>-0.798694</td>\n",
       "      <td>1.088510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058012</td>\n",
       "      <td>-1.163916</td>\n",
       "      <td>-1.986077</td>\n",
       "      <td>-0.588955</td>\n",
       "      <td>-1.235591</td>\n",
       "      <td>0.133469</td>\n",
       "      <td>-1.245607</td>\n",
       "      <td>0.229634</td>\n",
       "      <td>0.780697</td>\n",
       "      <td>-1.091630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18777</th>\n",
       "      <td>1.070572</td>\n",
       "      <td>-0.726081</td>\n",
       "      <td>-0.387005</td>\n",
       "      <td>0.655887</td>\n",
       "      <td>1.493963</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>0.070169</td>\n",
       "      <td>0.472378</td>\n",
       "      <td>2.685177</td>\n",
       "      <td>-1.384717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946140</td>\n",
       "      <td>-0.973980</td>\n",
       "      <td>-0.223580</td>\n",
       "      <td>-0.356280</td>\n",
       "      <td>-0.885449</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>-0.878716</td>\n",
       "      <td>1.040465</td>\n",
       "      <td>0.600961</td>\n",
       "      <td>-0.739647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18778</th>\n",
       "      <td>-0.072154</td>\n",
       "      <td>0.633303</td>\n",
       "      <td>1.763581</td>\n",
       "      <td>0.601012</td>\n",
       "      <td>1.569710</td>\n",
       "      <td>-2.062042</td>\n",
       "      <td>-0.331430</td>\n",
       "      <td>-1.444276</td>\n",
       "      <td>-0.870150</td>\n",
       "      <td>-1.154004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.460884</td>\n",
       "      <td>-1.307450</td>\n",
       "      <td>-2.513327</td>\n",
       "      <td>-0.620305</td>\n",
       "      <td>-0.495751</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>-0.805376</td>\n",
       "      <td>0.472169</td>\n",
       "      <td>0.548491</td>\n",
       "      <td>-0.195357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18779 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F0        F1        F2        F3        F4        F5        F6  \\\n",
       "0     -0.547340  0.321155 -0.521609 -0.667134  1.194584  0.616334  0.952861   \n",
       "1      1.179351 -0.186618 -0.383540  0.521422  0.035439 -0.219021 -0.590066   \n",
       "2      0.822423  0.548955  0.388522  0.699507 -0.212613  0.096057  1.051729   \n",
       "3      0.316304 -0.021830  0.921788 -0.440276 -0.773590  0.108143  0.597496   \n",
       "4     -0.079486  0.536734  0.968131  0.749729 -0.760875  1.116711  0.156330   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "18774  1.010972 -0.970312 -0.305139  0.319521  0.721568 -1.896508  2.487564   \n",
       "18775 -0.278320  0.159152  0.674553  0.703293  0.929658 -0.912538 -0.849352   \n",
       "18776 -1.290143  0.638520  0.265700  0.290224  1.114895  0.539747 -0.968946   \n",
       "18777  1.070572 -0.726081 -0.387005  0.655887  1.493963  0.013522  0.070169   \n",
       "18778 -0.072154  0.633303  1.763581  0.601012  1.569710 -2.062042 -0.331430   \n",
       "\n",
       "             F7        F8        F9  ...   CPerf10    CPrud5    CPrud9  \\\n",
       "0      0.101727 -0.934818 -1.044904  ... -0.474098 -0.721388 -0.285091   \n",
       "1     -0.723844 -0.279441 -0.971966  ... -0.116680 -0.243137 -0.081703   \n",
       "2      0.317545 -0.561819  0.342269  ...  0.396497  0.136460  0.269999   \n",
       "3      0.309328 -0.112767  0.348973  ...  0.329783  0.600764  0.424140   \n",
       "4     -0.349707  0.796320  1.484557  ...  0.511115  0.728974  0.152728   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "18774  1.883651 -1.879294  0.393940  ...  0.903710  0.234680  0.801625   \n",
       "18775  0.705957 -0.800981  1.010020  ... -0.031123 -0.192895 -0.792991   \n",
       "18776 -1.738070 -0.798694  1.088510  ... -0.058012 -1.163916 -1.986077   \n",
       "18777  0.472378  2.685177 -1.384717  ... -0.946140 -0.973980 -0.223580   \n",
       "18778 -1.444276 -0.870150 -1.154004  ... -1.460884 -1.307450 -2.513327   \n",
       "\n",
       "         OAesA6   OAesA10    OInqu1    OAesA7    OInqu3    OAesA1    ESent6  \n",
       "0      0.083817  0.646170  0.278937  0.838833  0.175011 -0.513915  0.754597  \n",
       "1     -0.381048 -0.275011  0.474022 -0.250842  0.422628  0.445666  0.332045  \n",
       "2     -0.344447  0.008495  0.252842 -0.041309  0.306829  0.291497  0.371646  \n",
       "3     -0.102456  0.527801 -0.461691  0.799929 -0.687216 -0.215589  0.205739  \n",
       "4      0.002362  0.042695 -1.186207  0.415763 -1.451052 -0.276623 -0.032219  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "18774 -0.212077  0.811664  0.724000  0.498172  0.862597  0.248693  0.861389  \n",
       "18775  1.365654  0.582033  0.206594  0.773841  0.064626 -1.269274  0.423509  \n",
       "18776 -0.588955 -1.235591  0.133469 -1.245607  0.229634  0.780697 -1.091630  \n",
       "18777 -0.356280 -0.885449  0.974000 -0.878716  1.040465  0.600961 -0.739647  \n",
       "18778 -0.620305 -0.495751  0.295734 -0.805376  0.472169  0.548491 -0.195357  \n",
       "\n",
       "[18779 rows x 91 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_pred_sample = encoder.predict(scaled_exp_data)[0]\n",
    "out=decoder.predict(latent_pred_sample)\n",
    "indata=pd.DataFrame(data=scaled_exp_data, columns=col_random)\n",
    "inout=pd.DataFrame(data=out, columns=col_random)\n",
    "factors=[]\n",
    "for i in range(latent_dim):\n",
    "    factors.append('F'+str(i))\n",
    "factor_names=list(factors)    \n",
    "#factor_names=list(['F0','F1','F2','F3','F4','F5','F6','F7','F8'])\n",
    "for i in range(latent_dim):\n",
    "    inout.insert(i,factor_names[i],latent_pred_sample[:,i],True)\n",
    "\n",
    "inout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d9433a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HSinc5</th>\n",
       "      <td>0.954978</td>\n",
       "      <td>-0.143635</td>\n",
       "      <td>-0.051908</td>\n",
       "      <td>-0.068579</td>\n",
       "      <td>-0.037559</td>\n",
       "      <td>-0.139564</td>\n",
       "      <td>0.084469</td>\n",
       "      <td>0.058701</td>\n",
       "      <td>-0.125888</td>\n",
       "      <td>-0.116720</td>\n",
       "      <td>-0.030707</td>\n",
       "      <td>-0.055340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMode5</th>\n",
       "      <td>0.911014</td>\n",
       "      <td>0.079431</td>\n",
       "      <td>-0.135378</td>\n",
       "      <td>0.048176</td>\n",
       "      <td>0.162115</td>\n",
       "      <td>0.117838</td>\n",
       "      <td>-0.013502</td>\n",
       "      <td>0.124366</td>\n",
       "      <td>0.100644</td>\n",
       "      <td>-0.199508</td>\n",
       "      <td>0.114846</td>\n",
       "      <td>0.089402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGree10</th>\n",
       "      <td>0.937507</td>\n",
       "      <td>0.021181</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.119691</td>\n",
       "      <td>0.135555</td>\n",
       "      <td>0.093482</td>\n",
       "      <td>0.068773</td>\n",
       "      <td>0.086179</td>\n",
       "      <td>-0.057912</td>\n",
       "      <td>-0.224261</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.003717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSinc3</th>\n",
       "      <td>0.985499</td>\n",
       "      <td>-0.050362</td>\n",
       "      <td>-0.112319</td>\n",
       "      <td>-0.143940</td>\n",
       "      <td>0.063966</td>\n",
       "      <td>-0.038243</td>\n",
       "      <td>-0.012936</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>-0.009322</td>\n",
       "      <td>0.069953</td>\n",
       "      <td>-0.004338</td>\n",
       "      <td>-0.035188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGree4</th>\n",
       "      <td>0.903605</td>\n",
       "      <td>0.140169</td>\n",
       "      <td>-0.162327</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.227880</td>\n",
       "      <td>0.071069</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.105493</td>\n",
       "      <td>-0.202227</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>0.055588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OInqu1</th>\n",
       "      <td>0.025350</td>\n",
       "      <td>-0.184236</td>\n",
       "      <td>-0.156530</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.332115</td>\n",
       "      <td>0.068930</td>\n",
       "      <td>-0.642672</td>\n",
       "      <td>0.254944</td>\n",
       "      <td>-0.069006</td>\n",
       "      <td>0.141452</td>\n",
       "      <td>0.143820</td>\n",
       "      <td>0.416692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAesA7</th>\n",
       "      <td>0.296484</td>\n",
       "      <td>-0.181343</td>\n",
       "      <td>0.059264</td>\n",
       "      <td>0.144525</td>\n",
       "      <td>0.058306</td>\n",
       "      <td>-0.011040</td>\n",
       "      <td>0.285917</td>\n",
       "      <td>0.775380</td>\n",
       "      <td>-0.154384</td>\n",
       "      <td>-0.051051</td>\n",
       "      <td>-0.348238</td>\n",
       "      <td>-0.046850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OInqu3</th>\n",
       "      <td>0.038329</td>\n",
       "      <td>-0.162564</td>\n",
       "      <td>-0.166421</td>\n",
       "      <td>0.175774</td>\n",
       "      <td>0.328713</td>\n",
       "      <td>0.089993</td>\n",
       "      <td>-0.796876</td>\n",
       "      <td>0.118050</td>\n",
       "      <td>-0.036430</td>\n",
       "      <td>0.138799</td>\n",
       "      <td>0.263484</td>\n",
       "      <td>0.074542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAesA1</th>\n",
       "      <td>-0.088624</td>\n",
       "      <td>-0.150037</td>\n",
       "      <td>-0.047931</td>\n",
       "      <td>-0.270942</td>\n",
       "      <td>-0.038022</td>\n",
       "      <td>-0.034233</td>\n",
       "      <td>-0.145220</td>\n",
       "      <td>-0.735743</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>0.061887</td>\n",
       "      <td>0.345142</td>\n",
       "      <td>-0.003732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESent6</th>\n",
       "      <td>0.329033</td>\n",
       "      <td>-0.248861</td>\n",
       "      <td>-0.145402</td>\n",
       "      <td>0.506779</td>\n",
       "      <td>0.148589</td>\n",
       "      <td>0.089599</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>-0.285392</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>-0.043742</td>\n",
       "      <td>-0.254701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               F0        F1        F2        F3        F4        F5        F6  \\\n",
       "HSinc5   0.954978 -0.143635 -0.051908 -0.068579 -0.037559 -0.139564  0.084469   \n",
       "HMode5   0.911014  0.079431 -0.135378  0.048176  0.162115  0.117838 -0.013502   \n",
       "HGree10  0.937507  0.021181  0.000690  0.119691  0.135555  0.093482  0.068773   \n",
       "HSinc3   0.985499 -0.050362 -0.112319 -0.143940  0.063966 -0.038243 -0.012936   \n",
       "HGree4   0.903605  0.140169 -0.162327 -0.000959  0.227880  0.071069  0.003905   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "OInqu1   0.025350 -0.184236 -0.156530  0.171200  0.332115  0.068930 -0.642672   \n",
       "OAesA7   0.296484 -0.181343  0.059264  0.144525  0.058306 -0.011040  0.285917   \n",
       "OInqu3   0.038329 -0.162564 -0.166421  0.175774  0.328713  0.089993 -0.796876   \n",
       "OAesA1  -0.088624 -0.150037 -0.047931 -0.270942 -0.038022 -0.034233 -0.145220   \n",
       "ESent6   0.329033 -0.248861 -0.145402  0.506779  0.148589  0.089599 -0.064735   \n",
       "\n",
       "               F7        F8        F9       F10       F11  \n",
       "HSinc5   0.058701 -0.125888 -0.116720 -0.030707 -0.055340  \n",
       "HMode5   0.124366  0.100644 -0.199508  0.114846  0.089402  \n",
       "HGree10  0.086179 -0.057912 -0.224261  0.006521  0.003717  \n",
       "HSinc3   0.011479 -0.009322  0.069953 -0.004338 -0.035188  \n",
       "HGree4   0.109971  0.105493 -0.202227  0.069151  0.055588  \n",
       "...           ...       ...       ...       ...       ...  \n",
       "OInqu1   0.254944 -0.069006  0.141452  0.143820  0.416692  \n",
       "OAesA7   0.775380 -0.154384 -0.051051 -0.348238 -0.046850  \n",
       "OInqu3   0.118050 -0.036430  0.138799  0.263484  0.074542  \n",
       "OAesA1  -0.735743  0.051226  0.061887  0.345142 -0.003732  \n",
       "ESent6   0.574598 -0.285392  0.086645 -0.043742 -0.254701  \n",
       "\n",
       "[79 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim=len(latent_pred_sample[0])\n",
    "max_items=240\n",
    "ffCorr=inout.corr()\n",
    "facLoad=ffCorr.iloc[latent_dim:max_items+latent_dim,0:latent_dim]\n",
    "idx=list(facLoad.index)\n",
    "col=list(facLoad.columns)\n",
    "factor_loadings=facLoad\n",
    "#Get the rotated Factors\n",
    "rotator = Rotator()\n",
    "facLoadRotate=rotator.fit_transform(facLoad)\n",
    "factor_loadings=pd.DataFrame(facLoadRotate,index=idx,columns=col)\n",
    "factor_loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd6d08bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000 -0.046858 -0.042716 -0.043525  0.055470 -0.028689  0.019551   \n",
      "1  -0.046858  1.000000  0.072833  0.018080  0.023681  0.024664 -0.039268   \n",
      "2  -0.042716  0.072833  1.000000 -0.055906 -0.024111  0.017312  0.032572   \n",
      "3  -0.043525  0.018080 -0.055906  1.000000  0.022771  0.035447 -0.049660   \n",
      "4   0.055470  0.023681 -0.024111  0.022771  1.000000  0.011767 -0.049581   \n",
      "5  -0.028689  0.024664  0.017312  0.035447  0.011767  1.000000  0.011722   \n",
      "6   0.019551 -0.039268  0.032572 -0.049660 -0.049581  0.011722  1.000000   \n",
      "7   0.047097 -0.004037  0.024481  0.056290  0.029111 -0.015073  0.017266   \n",
      "8  -0.026079 -0.007951 -0.042596 -0.008002 -0.031079 -0.023722 -0.033388   \n",
      "9  -0.045010 -0.095634 -0.046343  0.062245  0.074916 -0.005808  0.003707   \n",
      "10  0.011080  0.004249 -0.033206 -0.007715  0.018165  0.010108 -0.033932   \n",
      "11 -0.009883 -0.003171 -0.000143  0.009286  0.018191  0.009436  0.012527   \n",
      "\n",
      "          7         8         9         10        11  \n",
      "0   0.047097 -0.026079 -0.045010  0.011080 -0.009883  \n",
      "1  -0.004037 -0.007951 -0.095634  0.004249 -0.003171  \n",
      "2   0.024481 -0.042596 -0.046343 -0.033206 -0.000143  \n",
      "3   0.056290 -0.008002  0.062245 -0.007715  0.009286  \n",
      "4   0.029111 -0.031079  0.074916  0.018165  0.018191  \n",
      "5  -0.015073 -0.023722 -0.005808  0.010108  0.009436  \n",
      "6   0.017266 -0.033388  0.003707 -0.033932  0.012527  \n",
      "7   1.000000 -0.041097  0.005164 -0.046875 -0.009735  \n",
      "8  -0.041097  1.000000  0.036812  0.055269  0.012010  \n",
      "9   0.005164  0.036812  1.000000  0.016836 -0.002623  \n",
      "10 -0.046875  0.055269  0.016836  1.000000  0.006334  \n",
      "11 -0.009735  0.012010 -0.002623  0.006334  1.000000  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get the rotated latent factors\n",
    "latent_pred = encoder.predict(scaled_exp_data)[0] @ rotator.rotation_ \n",
    "#print(latent_pred)\n",
    "#pearson_coef, p_value = stats.pearsonr(latent_pred[:,0], latent_pred[:,2])\n",
    "#print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)\n",
    "corr_df = pd.DataFrame(data=latent_pred)\n",
    "corr = corr_df.corr()\n",
    "cluster_plot=sn.clustermap(corr, cmap='bwr', center=0)\n",
    "#cluster_plot.fig.suptitle('')\n",
    "node=str(hidden_nodes)\n",
    "cluster_plot.ax_heatmap.set_title('Correlations Between 12 Factors / '+ node+' Middle Layer Hidden Nodes')\n",
    "#cluster_plot.title('Basic 3 Factors Correlation Dendrogram)            \n",
    "#cluster_plot.savefig(\"Big5ClusterReluGreat1.png\")\n",
    "print(corr)\n",
    "corr=corr.round(2)\n",
    "corr.to_csv(CurrentFilename+'corrOfRotatedFactors2.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d50d2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               F0        F1        F2        F3        F4        F5        F6  \\\n",
      "HSinc5   0.954978 -0.143635 -0.051908 -0.068579 -0.037559 -0.139564  0.084469   \n",
      "HMode5   0.911014  0.079431 -0.135378  0.048176  0.162115  0.117838 -0.013502   \n",
      "HGree10  0.937507  0.021181  0.000690  0.119691  0.135555  0.093482  0.068773   \n",
      "HSinc3   0.985499 -0.050362 -0.112319 -0.143940  0.063966 -0.038243 -0.012936   \n",
      "HGree4   0.903605  0.140169 -0.162327 -0.000959  0.227880  0.071069  0.003905   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "OInqu1   0.025350 -0.184236 -0.156530  0.171200  0.332115  0.068930 -0.642672   \n",
      "OAesA7   0.296484 -0.181343  0.059264  0.144525  0.058306 -0.011040  0.285917   \n",
      "OInqu3   0.038329 -0.162564 -0.166421  0.175774  0.328713  0.089993 -0.796876   \n",
      "OAesA1  -0.088624 -0.150037 -0.047931 -0.270942 -0.038022 -0.034233 -0.145220   \n",
      "ESent6   0.329033 -0.248861 -0.145402  0.506779  0.148589  0.089599 -0.064735   \n",
      "\n",
      "               F7        F8        F9       F10       F11  \n",
      "HSinc5   0.058701 -0.125888 -0.116720 -0.030707 -0.055340  \n",
      "HMode5   0.124366  0.100644 -0.199508  0.114846  0.089402  \n",
      "HGree10  0.086179 -0.057912 -0.224261  0.006521  0.003717  \n",
      "HSinc3   0.011479 -0.009322  0.069953 -0.004338 -0.035188  \n",
      "HGree4   0.109971  0.105493 -0.202227  0.069151  0.055588  \n",
      "...           ...       ...       ...       ...       ...  \n",
      "OInqu1   0.254944 -0.069006  0.141452  0.143820  0.416692  \n",
      "OAesA7   0.775380 -0.154384 -0.051051 -0.348238 -0.046850  \n",
      "OInqu3   0.118050 -0.036430  0.138799  0.263484  0.074542  \n",
      "OAesA1  -0.735743  0.051226  0.061887  0.345142 -0.003732  \n",
      "ESent6   0.574598 -0.285392  0.086645 -0.043742 -0.254701  \n",
      "\n",
      "[79 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "factor_columns=list(factor_loadings.columns)\n",
    "factor_loadings_abs=factor_loadings.abs()\n",
    "\n",
    "sorted_factor_loadings=factor_loadings\n",
    "\n",
    "print(sorted_factor_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b03d1328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9854993308074276\n",
      "                                                   content    F0    F1    F2  \\\n",
      "HSinc3    tell other people what they want to hear so t...  0.99 -0.05 -0.11   \n",
      "HSinc5           switch my loyalties when i  feel like it.  0.95 -0.14 -0.05   \n",
      "HGree10                   am out for my own personal gain.  0.94  0.02  0.00   \n",
      "HMode5    would like to have more power than other people.  0.91  0.08 -0.14   \n",
      "HGree4                       have a strong need for power.  0.90  0.14 -0.16   \n",
      "HFair7                                 cheat to get ahead.  0.90 -0.06 -0.14   \n",
      "HSinc7                 pretend to be concerned for others.  0.88 -0.04  0.00   \n",
      "AGent10                    criticize others' shortcomings.  0.78 -0.01  0.11   \n",
      "AGent8                                speak ill of others.  0.72 -0.05  0.10   \n",
      "ESent6                       rarely cry during sad movies.  0.33 -0.25 -0.15   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "HSinc3  -0.14  0.06 -0.04 -0.01  0.01 -0.01  0.07 -0.00 -0.04  \n",
      "HSinc5  -0.07 -0.04 -0.14  0.08  0.06 -0.13 -0.12 -0.03 -0.06  \n",
      "HGree10  0.12  0.14  0.09  0.07  0.09 -0.06 -0.22  0.01  0.00  \n",
      "HMode5   0.05  0.16  0.12 -0.01  0.12  0.10 -0.20  0.11  0.09  \n",
      "HGree4  -0.00  0.23  0.07  0.00  0.11  0.11 -0.20  0.07  0.06  \n",
      "HFair7  -0.05 -0.18 -0.05  0.12  0.07 -0.06 -0.14 -0.06  0.00  \n",
      "HSinc7   0.10 -0.00 -0.14  0.01  0.18 -0.33 -0.17 -0.12 -0.12  \n",
      "AGent10  0.00  0.13  0.04 -0.16  0.14 -0.07 -0.54 -0.08  0.01  \n",
      "AGent8  -0.23 -0.11  0.04  0.00  0.07  0.05 -0.62 -0.11  0.03  \n",
      "ESent6   0.51  0.15  0.09 -0.06  0.57 -0.29  0.09 -0.04 -0.25  \n",
      "-0.6982191749445237\n",
      "                                                   content    F0    F1    F2  \\\n",
      "CPerf10                  prefer to just let things happen. -0.05  0.70  0.11   \n",
      "AGent2                           take things as they come.  0.01  0.70  0.33   \n",
      "HGree2         don't strive for elegance in my appearance.  0.33  0.48 -0.03   \n",
      "CPrud5     do things without thinking of the consequences. -0.29  0.47  0.30   \n",
      "CPrud9      don't know why i  do some of the things i  do. -0.27  0.46  0.18   \n",
      "CPrud4                  jump into things without thinking. -0.25  0.44  0.44   \n",
      "OInqu9    don't bother worrying about political and soc... -0.15  0.43  0.04   \n",
      "OInqu10              will not probe deeply into a subject. -0.09  0.38 -0.07   \n",
      "OAesA4                   enjoy feeling close to the earth.  0.32  0.27  0.44   \n",
      "OInqu5             find political discussions interesting. -0.12 -0.26  0.08   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "CPerf10  0.05  0.47 -0.01 -0.22  0.10  0.07 -0.38  0.06 -0.10  \n",
      "AGent2  -0.28  0.18 -0.07 -0.05  0.09 -0.18 -0.43 -0.07 -0.12  \n",
      "HGree2  -0.02  0.33  0.03 -0.06 -0.55  0.34  0.00 -0.02  0.01  \n",
      "CPrud5   0.32  0.51  0.25 -0.24 -0.08 -0.26  0.14  0.01  0.11  \n",
      "CPrud9   0.67  0.30  0.16 -0.22 -0.03 -0.01  0.05 -0.08  0.10  \n",
      "CPrud4   0.35  0.43  0.26 -0.17 -0.03 -0.35  0.07 -0.08  0.10  \n",
      "OInqu9  -0.04 -0.05 -0.05 -0.78 -0.22  0.17 -0.05 -0.02  0.24  \n",
      "OInqu10  0.18  0.14  0.08 -0.75 -0.08  0.08 -0.14  0.30  0.20  \n",
      "OAesA4   0.13 -0.19  0.03  0.16  0.46 -0.07 -0.25 -0.17 -0.42  \n",
      "OInqu5  -0.10 -0.01  0.09  0.87  0.04 -0.20 -0.03  0.04 -0.24  \n",
      "-0.9091611647238174\n",
      "                                                   content    F0    F1    F2  \\\n",
      "EFear6                      like to do frightening things. -0.27  0.10  0.91   \n",
      "EFear8                          love dangerous situations. -0.27  0.09  0.89   \n",
      "EFear5    would never go riding down a stretch of rapid... -0.04  0.07 -0.88   \n",
      "EFear10                          am willing to take risks. -0.10  0.11  0.85   \n",
      "EFear9    would be good at rescuing people from a burni...  0.08 -0.05  0.81   \n",
      "OInqu2               would love to explore strange places.  0.00  0.16  0.73   \n",
      "EFear3    would fear walking in a high-crime part of a ...  0.06  0.06 -0.72   \n",
      "OAesA9                               do not like concerts. -0.22 -0.03 -0.45   \n",
      "OAesA4                   enjoy feeling close to the earth.  0.32  0.27  0.44   \n",
      "CPrud4                  jump into things without thinking. -0.25  0.44  0.44   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "EFear6  -0.15  0.04  0.06  0.08 -0.00 -0.12 -0.03 -0.09  0.07  \n",
      "EFear8  -0.15  0.07  0.07  0.00  0.00 -0.17 -0.00 -0.12  0.10  \n",
      "EFear5   0.30 -0.07  0.06 -0.17 -0.13  0.20  0.07  0.04  0.05  \n",
      "EFear10 -0.30 -0.08  0.01  0.14  0.06 -0.30 -0.09 -0.20  0.03  \n",
      "EFear9  -0.32 -0.18  0.06  0.11 -0.08 -0.26 -0.22 -0.14 -0.15  \n",
      "OInqu2   0.02 -0.03 -0.13  0.18  0.26 -0.06 -0.07 -0.26 -0.18  \n",
      "EFear3   0.55 -0.11 -0.10 -0.17  0.09  0.09  0.04  0.03 -0.15  \n",
      "OAesA9  -0.04 -0.06  0.20 -0.14 -0.62  0.49  0.01 -0.00 -0.18  \n",
      "OAesA4   0.13 -0.19  0.03  0.16  0.46 -0.07 -0.25 -0.17 -0.42  \n",
      "CPrud4   0.35  0.43  0.26 -0.17 -0.03 -0.35  0.07 -0.08  0.10  \n",
      "-0.9659079105397044\n",
      "                                                   content    F0    F1    F2  \\\n",
      "EAnxi4    get upset by unpleasant thoughts that come in...  0.04  0.07 -0.08   \n",
      "EAnxi1    often worry about things that turn out to be ... -0.07  0.05 -0.12   \n",
      "EAnxi3                            get stressed out easily. -0.08 -0.06 -0.13   \n",
      "EAnxi2                                 worry about things.  0.01 -0.06 -0.17   \n",
      "EDepe1                                   need reassurance. -0.07  0.05 -0.17   \n",
      "EAnxi5                                       panic easily. -0.05 -0.00 -0.30   \n",
      "EAnxi6                                       rarely worry. -0.05  0.17  0.17   \n",
      "EDepe8                                       seek support.  0.06  0.09 -0.13   \n",
      "ESent10                              seldom get emotional. -0.26  0.14  0.10   \n",
      "CPrud9      don't know why i  do some of the things i  do. -0.27  0.46  0.18   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "EAnxi4   0.97  0.03  0.02 -0.12  0.16  0.01  0.14 -0.06 -0.07  \n",
      "EAnxi1   0.95  0.01  0.01 -0.04 -0.01  0.13  0.05 -0.01  0.12  \n",
      "EAnxi3   0.95  0.02  0.07 -0.02  0.06  0.17  0.29  0.03  0.05  \n",
      "EAnxi2   0.93 -0.07 -0.05  0.03  0.06  0.12  0.13 -0.01  0.06  \n",
      "EDepe1   0.92  0.05 -0.11 -0.12  0.19 -0.11 -0.04  0.07 -0.11  \n",
      "EAnxi5   0.92  0.16  0.10 -0.16  0.06  0.10  0.22  0.10  0.04  \n",
      "EAnxi6  -0.89  0.06  0.06 -0.05 -0.08 -0.15 -0.22  0.00 -0.06  \n",
      "EDepe8   0.81  0.02 -0.13 -0.11  0.24 -0.44 -0.09 -0.05 -0.15  \n",
      "ESent10 -0.74 -0.18 -0.07  0.09 -0.38  0.28 -0.30  0.07  0.15  \n",
      "CPrud9   0.67  0.30  0.16 -0.22 -0.03 -0.01  0.05 -0.08  0.10  \n",
      "0.9362111957036635\n",
      "                                                 content    F0    F1    F2  \\\n",
      "CPrud3                    do things according to a plan.  0.03  0.05  0.11   \n",
      "CPerf2             continue until everything is perfect.  0.18  0.07 -0.08   \n",
      "CPrud2                     make plans and stick to them. -0.05  0.07 -0.01   \n",
      "COrga3                                       like order.  0.05 -0.05  0.20   \n",
      "CDili3                           am exacting in my work.  0.13  0.11 -0.07   \n",
      "COrga1                                 keep things tidy. -0.02 -0.00  0.00   \n",
      "CPrud1                                   avoid mistakes.  0.16  0.07  0.06   \n",
      "COrga4                                  like to tidy up. -0.00 -0.07 -0.08   \n",
      "CDili1                 push myself very hard to succeed. -0.03  0.18 -0.25   \n",
      "CPrud5   do things without thinking of the consequences.  0.29 -0.47 -0.30   \n",
      "\n",
      "          F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "CPrud3 -0.02  0.94  0.10 -0.03  0.11  0.00  0.02 -0.07  0.03  \n",
      "CPerf2 -0.13  0.92 -0.04 -0.10  0.01 -0.05  0.04  0.14 -0.09  \n",
      "CPrud2  0.10  0.92  0.13 -0.04  0.07  0.11  0.08 -0.03 -0.11  \n",
      "COrga3 -0.06  0.88 -0.02 -0.06  0.07 -0.08  0.01 -0.14  0.22  \n",
      "CDili3  0.13  0.88  0.01 -0.29  0.02 -0.04  0.02  0.20 -0.05  \n",
      "COrga1  0.15  0.86 -0.21  0.10 -0.14 -0.07  0.10 -0.14  0.11  \n",
      "CPrud1  0.09  0.85  0.20 -0.20  0.12 -0.20  0.06  0.15 -0.01  \n",
      "COrga4  0.04  0.82 -0.27  0.09 -0.24  0.04  0.13 -0.12  0.16  \n",
      "CDili1 -0.02  0.81 -0.00 -0.20  0.01  0.14  0.04  0.19 -0.26  \n",
      "CPrud5 -0.32 -0.51 -0.25  0.24  0.08  0.26 -0.14 -0.01 -0.11  \n",
      "-0.4779616311867979\n",
      "                                                   content    F0    F1    F2  \\\n",
      "AForg1                                    love my enemies.  0.06  0.08  0.33   \n",
      "OUnco2       know that my ideas sometimes surprise people. -0.22  0.10  0.30   \n",
      "COrga4                                    like to tidy up.  0.00  0.07  0.08   \n",
      "CPrud4                  jump into things without thinking. -0.25  0.44  0.44   \n",
      "CPrud5     do things without thinking of the consequences. -0.29  0.47  0.30   \n",
      "HSinc10   let people push me around to help them feel i... -0.05  0.12  0.04   \n",
      "COrga1                                   keep things tidy.  0.02  0.00 -0.00   \n",
      "OAesA9                               do not like concerts. -0.22 -0.03 -0.45   \n",
      "AForg4            am nice to people i  should be angry at.  0.17  0.03  0.12   \n",
      "CPrud1                                     avoid mistakes. -0.16 -0.07 -0.06   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "AForg1  -0.05 -0.07  0.48  0.19  0.02 -0.20 -0.73 -0.14  0.02  \n",
      "OUnco2   0.00  0.02  0.28  0.30 -0.07 -0.18 -0.11 -0.69 -0.02  \n",
      "COrga4  -0.04 -0.82  0.27 -0.09  0.24 -0.04 -0.13  0.12 -0.16  \n",
      "CPrud4   0.35  0.43  0.26 -0.17 -0.03 -0.35  0.07 -0.08  0.10  \n",
      "CPrud5   0.32  0.51  0.25 -0.24 -0.08 -0.26  0.14  0.01  0.11  \n",
      "HSinc10  0.61  0.12  0.23 -0.08  0.01  0.11 -0.65  0.13  0.06  \n",
      "COrga1  -0.15 -0.86  0.21 -0.10  0.14  0.07 -0.10  0.14 -0.11  \n",
      "OAesA9  -0.04 -0.06  0.20 -0.14 -0.62  0.49  0.01 -0.00 -0.18  \n",
      "AForg4   0.35 -0.06  0.20  0.03  0.10 -0.14 -0.84 -0.03  0.03  \n",
      "CPrud1  -0.09 -0.85 -0.20  0.20 -0.12  0.20 -0.06 -0.15  0.01  \n",
      "-0.8700912594374988\n",
      "                                                   content    F0    F1    F2  \\\n",
      "OInqu5             find political discussions interesting. -0.12 -0.26  0.08   \n",
      "OInqu4                  love to read challenging material.  0.04  0.11  0.17   \n",
      "OInqu8                   avoid difficult reading material. -0.13 -0.04 -0.12   \n",
      "OInqu3                           enjoy intellectual games. -0.04  0.16  0.17   \n",
      "OAesA5              have read the great literary classics.  0.04  0.03  0.22   \n",
      "OInqu9    don't bother worrying about political and soc... -0.15  0.43  0.04   \n",
      "OInqu10              will not probe deeply into a subject. -0.09  0.38 -0.07   \n",
      "OInqu1                           am interested in science. -0.03  0.18  0.16   \n",
      "OUnco2       know that my ideas sometimes surprise people. -0.22  0.10  0.30   \n",
      "CDili3                             am exacting in my work. -0.13 -0.11  0.07   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "OInqu5  -0.10 -0.01  0.09  0.87  0.04 -0.20 -0.03  0.04 -0.24  \n",
      "OInqu4  -0.07 -0.15  0.03  0.83  0.13  0.01 -0.05 -0.25  0.27  \n",
      "OInqu8   0.12  0.07  0.02 -0.80 -0.15 -0.03 -0.01  0.25 -0.31  \n",
      "OInqu3  -0.18 -0.33 -0.09  0.80 -0.12  0.04 -0.14 -0.26 -0.07  \n",
      "OAesA5  -0.01 -0.13  0.05  0.78  0.38 -0.01 -0.04 -0.22  0.29  \n",
      "OInqu9  -0.04 -0.05 -0.05 -0.78 -0.22  0.17 -0.05 -0.02  0.24  \n",
      "OInqu10  0.18  0.14  0.08 -0.75 -0.08  0.08 -0.14  0.30  0.20  \n",
      "OInqu1  -0.17 -0.33 -0.07  0.64 -0.25  0.07 -0.14 -0.14 -0.42  \n",
      "OUnco2   0.00  0.02  0.28  0.30 -0.07 -0.18 -0.11 -0.69 -0.02  \n",
      "CDili3  -0.13 -0.88 -0.01  0.29 -0.02  0.04 -0.02 -0.20  0.05  \n",
      "0.8564504324277875\n",
      "                                                   content    F0    F1    F2  \\\n",
      "OAesA10          do not enjoy watching dance performances.  0.28 -0.09  0.10   \n",
      "OAesA7    seldom notice the emotional aspects of painti...  0.30 -0.18  0.06   \n",
      "OAesA6                                    do not like art.  0.08  0.15 -0.00   \n",
      "OAesA1                   believe in the importance of art. -0.09 -0.15 -0.05   \n",
      "OAesA9                               do not like concerts.  0.22  0.03  0.45   \n",
      "ESent6                       rarely cry during sad movies.  0.33 -0.25 -0.15   \n",
      "HGree2         don't strive for elegance in my appearance. -0.33 -0.48  0.03   \n",
      "OAesA4                   enjoy feeling close to the earth. -0.32 -0.27 -0.44   \n",
      "OAesA5              have read the great literary classics. -0.04 -0.03 -0.22   \n",
      "ESent10                              seldom get emotional.  0.26 -0.14 -0.10   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "OAesA10  0.19 -0.02 -0.01  0.10  0.86 -0.27 -0.15 -0.08  0.00  \n",
      "OAesA7   0.14  0.06 -0.01  0.29  0.78 -0.15 -0.05 -0.35 -0.05  \n",
      "OAesA6   0.23  0.07  0.02  0.04  0.74  0.01 -0.02 -0.26  0.05  \n",
      "OAesA1  -0.27 -0.04 -0.03 -0.15 -0.74  0.05  0.06  0.35 -0.00  \n",
      "OAesA9   0.04  0.06 -0.20  0.14  0.62 -0.49 -0.01  0.00  0.18  \n",
      "ESent6   0.51  0.15  0.09 -0.06  0.57 -0.29  0.09 -0.04 -0.25  \n",
      "HGree2   0.02 -0.33 -0.03  0.06  0.55 -0.34 -0.00  0.02 -0.01  \n",
      "OAesA4  -0.13  0.19 -0.03 -0.16 -0.46  0.07  0.25  0.17  0.42  \n",
      "OAesA5   0.01  0.13 -0.05 -0.78 -0.38  0.01  0.04  0.22 -0.29  \n",
      "ESent10  0.74  0.18  0.07 -0.09  0.38 -0.28  0.30 -0.07 -0.15  \n",
      "0.9830817341876623\n",
      "                                                  content    F0    F1    F2  \\\n",
      "XSoci3                                      love to chat. -0.00 -0.15 -0.12   \n",
      "XExpr1                                        talk a lot.  0.08 -0.01 -0.07   \n",
      "XExpr6                                  don't talk a lot.  0.01 -0.10  0.04   \n",
      "XExpr8                                        say little.  0.01 -0.13  0.02   \n",
      "XSoci6   seem to derive less enjoyment from interactin...  0.24 -0.01  0.13   \n",
      "XSoci1    usually like to spend my free time with people. -0.11 -0.09 -0.19   \n",
      "XSoci8   would not enjoy a job that involves a lot of ...  0.13 -0.03  0.25   \n",
      "XSocB3                    feel comfortable around people. -0.18 -0.10 -0.14   \n",
      "XSocB2          don't mind being the center of attention.  0.31  0.08 -0.19   \n",
      "OAesA9                              do not like concerts.  0.22  0.03  0.45   \n",
      "\n",
      "          F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "XSoci3 -0.15  0.01  0.00  0.03 -0.06  0.98  0.13  0.14  0.05  \n",
      "XExpr1 -0.11 -0.08 -0.16 -0.10 -0.04  0.98 -0.09  0.18 -0.01  \n",
      "XExpr6 -0.06  0.10  0.15  0.13  0.02 -0.97  0.16 -0.14  0.01  \n",
      "XExpr8 -0.06  0.11  0.16  0.14  0.04 -0.96  0.20 -0.14  0.01  \n",
      "XSoci6 -0.06  0.02 -0.10 -0.07  0.13 -0.94 -0.16  0.01 -0.01  \n",
      "XSoci1 -0.08  0.03  0.12  0.08 -0.06  0.94  0.22 -0.05 -0.01  \n",
      "XSoci8 -0.17 -0.02 -0.06  0.07  0.14 -0.94 -0.17 -0.03  0.01  \n",
      "XSocB3  0.20  0.08  0.08  0.03 -0.08  0.93  0.27  0.02  0.01  \n",
      "XSocB2  0.15  0.02  0.03 -0.06 -0.09  0.90  0.05  0.19  0.00  \n",
      "OAesA9  0.04  0.06 -0.20  0.14  0.62 -0.49 -0.01  0.00  0.18  \n",
      "0.9274576664186648\n",
      "                                                   content    F0    F1    F2  \\\n",
      "APati1    find that it takes a lot to make me feel angr... -0.22 -0.08 -0.03   \n",
      "APati2                      rarely feel angry with people. -0.27 -0.01 -0.01   \n",
      "APati5                                     seldom get mad. -0.19  0.00  0.03   \n",
      "APati4                               rarely get irritated. -0.19 -0.01 -0.01   \n",
      "APati3                        am usually a patient person. -0.28 -0.17  0.00   \n",
      "AForg4            am nice to people i  should be angry at. -0.17 -0.03 -0.12   \n",
      "AGent4                      have a good word for everyone. -0.27 -0.07 -0.17   \n",
      "AForg1                                    love my enemies. -0.06 -0.08 -0.33   \n",
      "HSinc10   let people push me around to help them feel i...  0.05 -0.12 -0.04   \n",
      "AGent8                                speak ill of others.  0.72 -0.05  0.10   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "APati1   0.33  0.09  0.07 -0.04  0.02  0.05  0.93  0.04  0.00  \n",
      "APati2   0.37  0.05  0.06 -0.01  0.00  0.10  0.90  0.02  0.00  \n",
      "APati5   0.45  0.06  0.14 -0.04  0.04  0.03  0.88  0.01  0.00  \n",
      "APati4   0.47  0.06  0.11  0.03  0.01  0.04  0.85 -0.00 -0.01  \n",
      "APati3   0.24  0.25  0.19 -0.04 -0.10 -0.08  0.85  0.05  0.10  \n",
      "AForg4  -0.35  0.06 -0.20 -0.03 -0.10  0.14  0.84  0.03 -0.03  \n",
      "AGent4  -0.14  0.15 -0.16 -0.08 -0.18  0.42  0.75  0.20  0.08  \n",
      "AForg1   0.05  0.07 -0.48 -0.19 -0.02  0.20  0.73  0.14 -0.02  \n",
      "HSinc10 -0.61 -0.12 -0.23  0.08 -0.01 -0.11  0.65 -0.13 -0.06  \n",
      "AGent8  -0.23 -0.11  0.04  0.00  0.07  0.05 -0.62 -0.11  0.03  \n",
      "-0.8652119668955981\n",
      "                                                   content    F0    F1    F2  \\\n",
      "OCrea7                     do not have a good imagination. -0.08  0.04 -0.05   \n",
      "OCrea1                           have a vivid imagination. -0.00  0.06  0.09   \n",
      "OCrea4                                   am full of ideas. -0.01  0.02  0.13   \n",
      "OCrea8                   have difficulty imagining things. -0.10  0.06 -0.06   \n",
      "OCrea2                         come up with something new. -0.00 -0.03  0.25   \n",
      "OUnco2       know that my ideas sometimes surprise people. -0.22  0.10  0.30   \n",
      "OAesA7    seldom notice the emotional aspects of painti... -0.30  0.18 -0.06   \n",
      "OAesA1                   believe in the importance of art.  0.09  0.15  0.05   \n",
      "OInqu10              will not probe deeply into a subject. -0.09  0.38 -0.07   \n",
      "OInqu2               would love to explore strange places.  0.00  0.16  0.73   \n",
      "\n",
      "           F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "OCrea7   0.00 -0.03  0.09 -0.06 -0.18  0.09  0.00  0.87 -0.01  \n",
      "OCrea1   0.15  0.04 -0.04  0.05  0.18 -0.05 -0.04 -0.86 -0.00  \n",
      "OCrea4  -0.03 -0.10  0.10  0.29  0.08 -0.18 -0.06 -0.86 -0.02  \n",
      "OCrea8   0.05 -0.02  0.14 -0.08 -0.21  0.04 -0.01  0.85 -0.03  \n",
      "OCrea2  -0.16 -0.13  0.14  0.28  0.08 -0.24 -0.12 -0.81 -0.01  \n",
      "OUnco2   0.00  0.02  0.28  0.30 -0.07 -0.18 -0.11 -0.69 -0.02  \n",
      "OAesA7  -0.14 -0.06  0.01 -0.29 -0.78  0.15  0.05  0.35  0.05  \n",
      "OAesA1   0.27  0.04  0.03  0.15  0.74 -0.05 -0.06 -0.35  0.00  \n",
      "OInqu10  0.18  0.14  0.08 -0.75 -0.08  0.08 -0.14  0.30  0.20  \n",
      "OInqu2   0.02 -0.03 -0.13  0.18  0.26 -0.06 -0.07 -0.26 -0.18  \n",
      "0.42025203455731225\n",
      "                                                  content    F0    F1    F2  \\\n",
      "OAesA4                  enjoy feeling close to the earth. -0.32 -0.27 -0.44   \n",
      "OInqu1                          am interested in science.  0.03 -0.18 -0.16   \n",
      "OInqu8                  avoid difficult reading material.  0.13  0.04  0.12   \n",
      "OAesA5             have read the great literary classics. -0.04 -0.03 -0.22   \n",
      "OInqu4                 love to read challenging material. -0.04 -0.11 -0.17   \n",
      "CDili1                  push myself very hard to succeed. -0.03  0.18 -0.25   \n",
      "ESent6                      rarely cry during sad movies.  0.33 -0.25 -0.15   \n",
      "OInqu5            find political discussions interesting.  0.12  0.26 -0.08   \n",
      "OInqu9   don't bother worrying about political and soc...  0.15 -0.43 -0.04   \n",
      "COrga3                                        like order.  0.05 -0.05  0.20   \n",
      "\n",
      "          F3    F4    F5    F6    F7    F8    F9   F10   F11  \n",
      "OAesA4 -0.13  0.19 -0.03 -0.16 -0.46  0.07  0.25  0.17  0.42  \n",
      "OInqu1  0.17  0.33  0.07 -0.64  0.25 -0.07  0.14  0.14  0.42  \n",
      "OInqu8 -0.12 -0.07 -0.02  0.80  0.15  0.03  0.01 -0.25  0.31  \n",
      "OAesA5  0.01  0.13 -0.05 -0.78 -0.38  0.01  0.04  0.22 -0.29  \n",
      "OInqu4  0.07  0.15 -0.03 -0.83 -0.13 -0.01  0.05  0.25 -0.27  \n",
      "CDili1 -0.02  0.81 -0.00 -0.20  0.01  0.14  0.04  0.19 -0.26  \n",
      "ESent6  0.51  0.15  0.09 -0.06  0.57 -0.29  0.09 -0.04 -0.25  \n",
      "OInqu5  0.10  0.01 -0.09 -0.87 -0.04  0.20  0.03 -0.04  0.24  \n",
      "OInqu9  0.04  0.05  0.05  0.78  0.22 -0.17  0.05  0.02 -0.24  \n",
      "COrga3 -0.06  0.88 -0.02 -0.06  0.07 -0.08  0.01 -0.14  0.22  \n"
     ]
    }
   ],
   "source": [
    "sortAllF=pd.DataFrame(columns=factor_columns)\n",
    "for i in range(latent_dim):\n",
    "   current_factor=sorted_factor_loadings.iloc[0:240,i]\n",
    "   #print(current_factor)\n",
    "   current_factor_abs=current_factor.abs()\n",
    "   current_factor_abs.sort_values(axis = 0, ascending = False, inplace = True, na_position ='last')      \n",
    "   idx=current_factor_abs[current_factor_abs>0.1].index\n",
    "   sorted_currentFactor=current_factor.loc[idx]\n",
    "   #print(sorted_currentFactor)\n",
    "\n",
    "   current_sortAllF=sorted_factor_loadings.loc[idx] \n",
    "   #print(current_sortAllF) \n",
    "   if(len(sorted_currentFactor)>0):\n",
    "      first=sorted_currentFactor.iloc[0]\n",
    "      print(first) \n",
    "      if(sorted_currentFactor.iloc[0]<0):\n",
    "         current_sortAllF *=(-1)\n",
    "      length_cf=sorted_currentFactor.size\n",
    "      #print(length_cf)\n",
    "      if(length_cf>15):\n",
    "         current_sortAllF_abs=current_sortAllF.abs()\n",
    "         #print(current_sortAllF_abs)\n",
    "\n",
    "         max_index = current_sortAllF_abs.idxmax(axis=1)\n",
    "         #print(max_index)\n",
    "         keep_idx = max_index[max_index == factor_columns[i]].index\n",
    "         #print(keep_idx)   \n",
    "         if(keep_idx.size > 10):    \n",
    "            current_sortAllF=current_sortAllF.loc[keep_idx]\n",
    "         else :\n",
    "            current_sortAllF =current_sortAllF.iloc[0:10]\n",
    "      \n",
    "      current_sortAllF=current_sortAllF.round(2)\n",
    "      code_content=code_book.loc[current_sortAllF.index]  \n",
    "      current_sortAllF.insert(0,'content',code_content.iloc[:,1],True)\n",
    "      print(current_sortAllF)\n",
    "      sortAllF=sortAllF.append(current_sortAllF)\n",
    "      #sortAllF=sortAllF.append(pd.DataFrame(data=factor_columns))\n",
    "      sortAllF=sortAllF.append(pd.DataFrame(range(1)))\n",
    "   #print(current_sortAllF)\n",
    "CurrentFilename=filename+'-FinalFactorRotatedLoadingsUnSorted'+'.csv'\n",
    "#print(sortAllF.columns)\n",
    "sortAllF.to_csv(CurrentFilename, index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72f17fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvsfilename=filename+'-FactorLoadings.csv'\n",
    "sorted_factor_loadings.to_csv(cvsfilename, index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdata.to_csv('dropdataGood2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "826ffe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26.247404309030063, 38.51002374912406)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x266.991 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # curve NELBO\n",
    "golden_size = lambda width: (width, 2. * width / (1 + np.sqrt(5)))\n",
    "fig, ax = plt.subplots(figsize=golden_size(6))\n",
    "hist_vae = {k:hist.history[k] for k in ('loss', 'val_loss')}\n",
    "hist_vae_df = pd.DataFrame(hist_vae)\n",
    "hist_vae_df.plot(ax=ax)\n",
    "\n",
    "ax.set_ylabel('NELBO')\n",
    "ax.set_xlabel('# epochs')\n",
    "\n",
    "ax.set_ylim(.99 * hist_vae_df[1:].values.min(),\n",
    "            1.1 * hist_vae_df[1:].values.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9(tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
